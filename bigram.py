# gpt: generative pretraining transformer; 
# recreating chatgpt from scratch 
# author: Matthew Ng @ust

# Attention is all you need: 
# train a transformer based model, character level

# input: with a given amount of data, we would like the transformer able to predict the next character after a given sequence of characters.  